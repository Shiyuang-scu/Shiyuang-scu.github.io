# 计算姬 合集

## 社会网络分析之实际应用

互联网，尤其是Web2.0在过去的十年飞速发展，其中社交网络作为Web2.0的重要组成部分极大的拉近了人们之间的举例，产生了新的合作和沟通方式，也变更了传统通过传统媒介的信息传播方式。在传统时代，传统的媒体通过单向传播由大V发声，将信息从单一的生产者传递给广泛的消费者。而社会网络中，一个用户既是消费者也是生产者，这也就是我们口中的UGC(user generated content)，在传播效率上也发生了翻天覆地的变化，据说在Twiiter上的传播速度已经大于了地震波的速度；此外在过去，每个人能建立起的社交关系非常有限，并且极大的受着空间的限制，大多社交关系的产生都是由于用户位于同一区域，例如同一公司，同一学校等等，基于兴趣的社交关系几乎不存在，而社交网络对社交关系产生了极大的影响。所以说社会网络真正的改善了人们的生活，这也是我痴迷于互联网的最大原因。
 
但是社会网络在过去的十年时间内一直都是以某种产品形态存在，社交网络分析作为数据应用的某一方向，往往被人认为不接地气，并无卵用。例如有一篇很经典的Paper大概是分析Twitter到底是一个社交网络还是一个网络媒体，切不谈产生的结论如何，但是这很难产生真正的商业价值；例如有学者专门研究不同社区的小世界理论/效应，其实也并无真正的生产应用。那么在这个系列文章中(不知道何时会太监)，我更希望和王婷一起来从实用性的角度来阐述社会网络分析的工业界效用。
 
社会网络其实是一张大的图结构，而图就是由节点和边之间组成，落实到具体的社会网络分析，节点就是用户，而边就是将他们联系到一起的因子，例如互相关注，例如共同兴趣等等。那么我们就先从节点本身说起。评价一个节点、一个用户、一个人有很多指标，其中最重要的指标就是节点的“重要性”。也就是一个人的重要性。如何说一个人重要呢？学术界有很多关于节点重要性的计算方式，但是在这里，我们更重要的是把这些公式与实际的生产环境联系起来。
 
计算方式1：节点的度数

这是最常用的计算方式，原因是因为这种计算方式最简单，也最泛化。具体的计算方式就是看一个点的度数，也就是和一个点连接的边数。我们落实到实际的物理意义上，就是将这个人与多少人“相关联”。
其实这一指标有很多的应用价值，但是也有很多的误区。我举个简单的例子，我们希望在微博上去找大V投放广告，那么自然想到最简单的办法就是找到关注数最多的用户去做广告投放。
再做一个稍微复杂的扩展，如果我们希望买一篇软文来推广我们的产品，于是我们需要选一个渠道来做我们的广告投放，但是我们知道网站和网站之间经常会有着“转载”，那么我们就需要把文章和文章之间建立起一个转载的关联，从而希望我们的文章能够最多地覆盖到更广泛的渠道。最简单的办法自然也是找那种最容易被转载的渠道。
再说一个具体的推荐算法的例子。当一个新用户刚刚进入到某一社交网络中时，我们需要为其推荐好友。那么最简单的推荐方式就是推荐被关注数最多的用户，原因无外乎有二：1. 被关注数越多说明质量越高。 2.被关注数越多说明兴趣越能被大众所接受于是越有可能为今后的兴趣迁移做准备。(当然，这也是一个很多人都忽略的坑。)
说到度数需要再稍微提一点，我们知道所有的社会网络，无论是新闻、条目还是用户的关注数，都是呈幂率分布的，所以我们在做社会分析的时候要非常注意到头部、中部和尾部的独立分析，并且我们实际应用时可以利用这一实际规律节省大部分的计算资源，提高计算效率。例如我们可以通过删除尾部数据减少目标数，同时在计算相似度时可以将头尾分开，从而避免数据倾斜的问题。
但是所有的这种方式其实都有一种致命的问题，我们都忽略了二次传播以及多次传播的重要性。
 
计算方式2：PageRank、PeopleRank

PageRank相信每个人都非常清楚，在之前我的搭档也写过一篇关于PageRank的文章，PageRank的最大好处就是通过迭代计算充分地考虑了多次传播的因素。
这一点对于做算法的同学听上去很简单，但是其实有着特别有趣的商业化应用。我们知道，大部分的大V的广告基本都是根据粉丝数来计费的，那么如果你的预算不足以请动Angelababy，这个时候该怎么办呢？Pagerank就是其中的算法之一，虽然说某位用户的粉丝数很少，但是她可能是某电影学院的学生，可能会是某某明星的同学，那么其实会有很多的明星指向她，所以其实她的微博也可能会在一定概率上被其他的明星所转播。这个时候算法就派上用场了，一般情况下我们可以对PageRank做一个略微的改进，在PageRank中，两点之间的权重取决于“出点”的度数，那么这里我们需要把度数换算成某明星可能转发该文章的概率，这个概率会取决于文章内容与明星标签的关联度，取决于这个明星关注的人数(即看到该文章的微博)等等。这就是用算法产生价值的很重要的一个点。
 
计算方式3：最短距离 & 集群中心点

在社会分析领域，有个评估节点的指标叫做betweenness，其实就是评估这个点到其他点的距离，他的核心应用在于，如果我从这个点开始传播，有多大的概率可以到达社区中所有的人。有些算法基础的都会知道这个计算量几乎是无法承受的，但是其实这也有很好的应用场景。
集群中心点这个词是我自己定义的，可能不恰当，其实就是整个集群中的Hub点，用图论语言描述，就是如果删除该节点，会将整个图变成若干个独立的子图。用平常的语言描述，就是说这个人可以将若干个不同群体的人联系起来，最简单的现实中的例子就是猎头。
那么他们到底有什么实际的作用呢？
之前罗辑思维中讲过一个案例，大意是说中国传媒有个女学生希望罗胖帮他做宣传，罗胖出了个难题说你要联系到100个人找到我，我就答应你的要求，最后这个女孩果然找到了100个不同的人找到了罗胖，成为了一个非常经典的案例。同理很简单，继续举上面投微博广告的例子，我没有足够的预算又希望能够让某个明星帮我转播微博，我能做什么事情呢？假设说我认为微博的三度衰减已经趋近于0，那么我需要找到的是关注我的，并且在三度以内可达该明星的社交关系，如果我找到所有这样的关系，相当于该明星有非常大的概率能够看到这条微博。这个例子可能还有些复杂，那么举个简单一些的。如果我希望投放某个广告，性价比最高的方式是什么？找到所有我希望触达的人，即目标用户(例如所有喜欢游泳的用户)，然后找到所以可以投广告方(例如某些明星，媒体等)，然后计算广告方和目标用户之间的平均最短距离，作为这些广告方的Betweenness，再通过加权方式与他本身的价钱相结合，就可以计算出这个用户的性价比。
那么对于集群中心点的应用就更加简单了，我在算法1中提到过，对于新用户，我们为他推荐入度最大的用户、推荐好评最多的文章、推荐红心最多的歌曲是最稳妥的方法，但是这都没有考虑到未来用户的兴趣迁移，也就是没有最大化用户的兴趣图谱。那么作为Hub点，最重要的特征是他连接着多个不同的兴趣群体，同时被多个兴趣群体所接受，于是我就可以通过这个Hub用户左右摇摆(即多叉树结构)，从而发散出该用户的最完整的兴趣图谱。
 
写在最后：
 
在第一篇文章中，我概述了针对社会网络分析部分中针对节点重要性的一些工业化应用，社会网络分析是个非常广泛的学科，其中包括关系分析、反作弊、社群发现、媒体挖掘等等，但是如何把这些学术上的研究转换为商业应用却是太多公司、太多算法工程师都忽略的地方，也希望接下来我们可以逐渐探讨，也希望我的搭档王婷博士可以有着更加深入的研究。

## 分层架构与公司组织

分层架构
 
1  我们先看传统的分层架构(Layer Pattern)，它是以结构层面对软件项目进行分层划分，将应用程序划分为多个子任务，让每个任务处于一个单独的架构层，完成独立的工作，常见的例子包括我们在项目中常常涉及的软件三层架构以及我们一直接触到的OSI五层/七层模型。分层架构听上去非常简单，但是我在这里要提一些理论上需要注意的地方：
 
2  第N层只能调用第N-1层的服务。这是分层架构最重要的一点，所以很多人把MVC与三层架构相混淆时请思考这一点，MVC模式中MVC之间互相耦合，Model在Controller和View之间传递，Controller处理View的逻辑，他们并不是一个分层的关系。而三层架构将用户界面层，业务逻辑层，数据访问层通过具体的接口方式彼此隔离，不存在跨层的依赖关系。
 
3  在第N-1层缓存第N层需要调用的数据。分层最大的诟病其实就在于层层调用而产生的性能消耗，所以对于分层模式来说，缓存是非常重要的一环。但是请一定注意一点，缓存是处于被调用方而非调用方，这一点有两个原因: 
<1> 调用方无需知道这一数据的来源，是数据库读取还是直接缓存提供 <2> 调用方维持数据缓存会遇到复杂的数据同步问题。
 
4  为每一层起名。这一点看上去会很奇怪，感觉像是流入了形式主义。其实这一点的更大的作用是，名字可以让设计者、使用者更加明确这一层的作用，避免出现层次的不清晰划分。
 
5  制定好每层的错误处理策略。在大学学习Java的异常处理时一直没有想清楚，异常处理部门throw的作用，当时觉得其实出错的时候打印出错误日志或者让程序异常终止不就可以了么，为什么需要抛出呢？后来结合到分层的架构才想清楚，在分层逻辑中，每一层都有自己的错误处理步骤，例如在数据访问层遇到数据访问异常可能需要尝试重连，如果依然有问题就向上抛出，那么落实到业务逻辑层可能需要的是访问脏数据或者第三方数据，如果依然有问题就向上抛出，真正需要捕获异常而Break程序或者提示用户的只有用户界面层而已。那么落实到更抽象的层面，我们需要考虑层与层之间的调用方式，从而决定了是以异常方式丢给用户，还是状态码，或者是具体的错误信息。
 
而落实到实际的应用层面，我们却需要对分层架构做出这样那样的妥协和改进：
 
1  层的穿透。在之前我提过，在标准的分层架构中，第N层只能调用第N-1层的服务，可是在一些场景中是不恰当的。分层的主要问题是性能损失，引起性能损失的原因包括层层调用而产生的网络消耗和方法调用成本，以及中间层必须维持抽象而产生的冗余成本。对于一些对性能要求较高的系统而言，例如操作系统，那么需要为了维持性能而做出跨层调用，但是需要做出平衡的是底层方法修改带来的维护成本 和 性能之间的平衡。
 
2  层与层之间的接口究竟抽样到何等程度。我们在实际工作中往往发现我们设计分层的目的之一是为了重用，但是实际重用性并不高；开发人员往往的理由在于现有的接口与目标需求并不匹配，所以需要新开接口。而接口开发人员的理由很简单，返回过多的字段(过多的抽象)会产生不必要的性能和网络消耗，那么如何平衡两者依然是我们需要平衡的艺术。
 
3  层与层之间建立共享数据、方法。我们希望尽可能地减少层与层之间的依赖，希望更好地保持数据同步(例如避免脏读)，我们可以在整个系统层面建立共享数据(例如共享内存)，从而提高效率。例如我们无法逃脱用户权限的逻辑，所以可以将Auth模块放在公共的服务器上供所有模块访问。
 
4  层与层之间的解耦。层与层解耦有很多方式，最简单的方式可以通过API调用的方式进行解耦，当然通过消息队列也是一种现代软件系统的变种方式。
 
5  MVC作为分层架构的退化。在互联网领域，我们已经越来越少听到三层架构了，而大部分从业者也开始逐渐把MVC当作为三层架构，当然这自有基础知识的欠缺，但是也确实容易造成这样的误会。互联网逻辑相对简单，复杂的地方基本都是HTML端相对复杂的逻辑，以及数据访问的优化，所以这时三层架构的业务逻辑层就已经与用户界面层的Controller等同到了一起，数据访问层与Model层混合到一起。当然对于小型项目无可厚非，但是我个人更加倾向于将数据访问层依然独立出来，成为互联网界更加知名的Service层，其实我无法说Service层是属于业务逻辑还是数据访问，原因有二： <1> 互联网对性能的极致追求，使得我们不便做过多的抽象，所以业务逻辑往往都被和数据库的SQL访问产生强依赖  <2> Service层往往需要自己管理数据的Cache，所以从这一点来说他也相当于混合了业务逻辑层和数据访问层的工作。
 
最后，我们从问题展开再回到问题本身，到底应该以功能层面分拆还是以软件结构进行分拆，该同事给出的答案是No Bullet，在这里我想更展开说一下，我们回到分层的目的，其实无外乎三者： 分工、重用、可维护。而软件的架构本身是强调“高内聚，低耦合”。所以我们在划分该架构时也要遵循上面的原则，那么更加标准的答案应该是优先功能划分，然后结构划分。例如CRM与统计功能彼此独立，那么应该将二者分开，是否应该划分的逻辑很简单，这两者之间有什么需要共享的模块(Service)，有多少重复的方法。但是过度的结构划分会产生重用性变低的情况，我曾经见过每个功能划分一个MVC，例如Note, User，这会造成更大的混乱。
 
公司架构
 
最近一年公司的快速成长，已经从几十人的小公司发展为150余人的公司，所以我进来花了更多精力去思考公司的组织结构问题，希望能让公司更加高效的运转。
 
其实公司的组织与软件架构是同样的逻辑：
 
1  高内聚低耦合。无论我们承认还是不承认，跨部门沟通永远是一个公司最大的痛，所以作为组织架构的设计，最重要的就是如何使跨部门沟通变得最少，或者只有一个接口来做这件事情。从这一点来看，也许我们需要对组织架构做更多的思考。
 
2  关于业务逻辑分还是软件功能分。这一点其实对应的是我们到底是以事业部的方式组织，还是以职责部门的方式组织。在我看来依然是同样的逻辑，当项目足够多的时候，一定要优先以事业部的方式划分，原因很简单，提高整个部门的内聚性，每当任何一个问题产生时，总会有一个中间人(事业部GM)来站出来平衡利益关系，这个利益包含技术和产品的博弈，技术和测试的博弈，产品和运营的博弈等等。之前我给老板讲过这样一个逻辑，为什么一个CEO下面最多只能有四到五个高管，因为每当两个高管进行跨部门合作沟通时，就需要一个利益无关人平衡双方关系，如果是5个人，那么就是(5*4 / 2
= 10)种组合关系，而当这个数字增加到10时，组合关系就变成了45种，这还没有算上三个部门合作的组合关系。这也是我为何一直认为扁平化组织关系并不可行的原因。
 
3  公共组件的搭建。我们思考下我们的软件架构是不是设置了太多的公共组件，例如我们认为认证模块是公共组件，转而一想好像数据访问也是公共组件，其实每个组件只有一到两个模块在调用。这个产生的原因在于我们基础架构的划分不合理。太多公司也是类似的问题，例如某大型互联网公司的公共技术部门，为何发挥不了作用，最大的原因在于这并不是一个公共技术，例如打算把统计平台做成一个公共技术，疏不知统计这件事情与业务紧密结合，真正抽象出来的应该是更好用的Hive和ETL工具罢了。我们需要把“公共部门”变得尽量薄，如果我们发现一个部门与太多部门之间都存在着调用关系，这时我们就需要思考是否组织结构不合适，或者是否该部门应该被分拆了。

## 由搜索引擎Google说起

今天Google成立了一家母公司-Alphabet，瘦身后的Google将成为Alphabet的一个全资子公司。大清早睁开眼就看到这条爆炸性消息，还么睡醒的我突然异常的兴奋和激动。Google从成立之初就不是一家传统公司，到如今Google更是变成一家伟大的公司，而Alphabet未来能带给我们什么，我简直不敢想象，Google， X-lab，投资公司Ventures & Capital，Fiber光纤，Nest智能家居，还有跟生命、抗衰老有关的黑科技Calico。同时Google调整了其组织架构后摆脱了之前的臃肿，并且并入了所有跟广告相关的业务，让其可以专注于发展自身的技术、业务和服务了，而Alphabet也可以尽情得dream big dreams。

其实Google在初创阶段的算法设计在如今看来是如此的简单，可对于当时来说却是一步巨大的技术飞跃，网页相关性排序做得不好就设计了一个Pagerank算法来帮助决策网页的重要性，Pagerank需要做大规模的矩阵计算，于是又设计了MapReduce并行计算框架。这些算法和框架的产生，无一不是从需求出发，使用最简单，好解释的方案来解决问题。

这就引出一个很多人都有的困惑，在做数据分析或数据挖掘的时候，解决一个具体问题究竟是用一个简单naive的算法还是用一个复杂fancy的算法。通常使用任何一个算法可能会改进一类问题，但也可能会对另一类情况产生负面影响。虽然一个复杂的算法在效率、准确性上有非常大的优势，然而相比简单算法，复杂算法在遇到问题时其分析的难度，追溯的复杂度都有可能为整个系统埋下不小的隐患。然而简单算法，虽然其效果有可能达不到100%，但实现时间更短，在初创时期能满足80%的效益，是可以接受的，剩下的问题可以之后慢慢来解决。

按理来说我一读PHD的应该崇尚高深的研究算法，但学术的深度毕竟与工业的实现相距甚远，工作时间久了，就越来越能体会到选择简单算法，而不是fancy算法应用于工业界的魅力之处。如果选择复杂的算法，尤其是复杂的机器学习算法，特别是对于一个问题，一上来就搞神经网络、深度学习之类的，像黑盒子一样不可解释，可能实现加训练模型再调个参数，三四五个月就过去了。我当然不是在黑机器学习的算法，我对算法始终是有一颗敬畏之心，总想有朝一日，把这些复杂算法应用到工业环境中，造福每一个互联网用户。当然也需要依赖于公司所处的阶段与战略，如果公司的基础设施搭建足够强大，而且也已经有了很多算法的积累，那么就可以在此基础上尝试更复杂的机器学习算法，例如Google、Baidu。如果公司还处于什么算法都没有用过的阶段，那naive的算法，设计一些规则可能就能有非常好的效果了，当数据维度越来越大以后，再逐步上一些数据挖掘、机器学习算法，也是较为合理的发展策略。

现在不论哪个公司都在提「大数据」，都想利用大数据概念来分一杯羹，可这些公司都真正达到了大数据的数据量了吗？显然是没有的，可能当产品的用户达到百万级别才称得上刚刚过了大数据门槛，真正的大数据量可能是上千万、上亿级别的用户量，日志数据至少T级别，甚至每分钟达到T级别。所以，很多公司的大数据道路还可以再等等。

当然在公司的初始阶段，如果能有一位数据专家来帮助指导数据平台的搭建，那是极好的，因为这样就不会出现当公司达到一定的规模，想分析一些数据来帮助公司的业务更近一层的时候，该存的数据没存到，或者积累的数据没办法进行分析，又要重新来设计数据平台再积累一遍数据的情况。

在合适的时候选择合适的算法，也许你就是下一个Google。

## 漫谈专家推荐

1.专家推荐的应用场景

A. 快速上线。快速上线一个推荐算法，有两种是最为有效的，最方便的当然是基于内容的推荐，我们分词，抽取Tag，计算User-Profile，然后做简单的匹配，从而就快速地上线了一个算法，但是我们也知道基于内容的推荐效果往往一般，具体的原因如果今后有机会，我愿意具体地来做个分析。那么另外一个容易的做法就是协同过滤，但是协同过滤最致命的问题有两个，第一是计算量太大，如果没有一个分布式计算平台基本没办法搞，另外就是数据的稀疏，基本上做协同过滤的第一步，或者说对于一个新产品来说，如果不降维，效果是惨不忍睹的。所以综上考虑，其实专家推荐是非常适合于解决问题的，方法简单，通过规则选择专家，计算M个用户和N(N远远小于M)个专家的相似度即可；

B. 冷启动。其实这一点非常像我在刚刚提到的数据稀疏度问题，那么专家推荐其实很好地解决了这样的情况。更尤其是在现在大多的社区产品中，大多采用的方式是邀请制，那么其实在新用户大量涌入之前，其实已经有了很多的专家。也就是说虽然用户和用户之间数据极其稀疏，但是用户和专家之间，是有着较高的重合度的，所以可以来做推荐。

C. 补充推荐。这一点我个人认为最大的用处还是在于推荐理由，例如豆瓣FM在最近半年新上线了“每日为你推荐”，如果我来设计这个产品，这个产品其实把推荐理由提升到了豆瓣FM前所未有的高度作用之上，因此如果是我来设计这个产品，我一定会考虑将专家推荐作为多种算法的补充融合到推荐算法当中。

2.专家推荐的算法缺陷

A. 倾向热门。在上一篇文章中，我介绍论文的作者通过数据说明了这样的一个观点：“the expert matrix is less sparse than the user matrix and more evenly distributed, both per user and per movie.” 也就是说专家的评分矩阵更加稠密，从优点来讲，这解决了数据稀疏性的问题；但是我们思考一下，数据的稠密导致的是热门Item更加的集中，也就是说，专家推荐会更加地倾向于推荐热门条目。为了验证这一结论，我们再丢出上一篇文章中的一个数据结论来证明：“50%普通用户对于一部电影的分数从0.5到1分之间不等，但是50%的专家用户对于一部电影的分数只有从0.7到1之间不等，由此说明专家用户对于电影的认知度更为统一”。

B. 数据偏移。这个道理很简单，我举一个简单的例子，我作为一个IT的专家用户，是否可以从我的最近评分中为大多数的IT从业者选择IT书籍，答案是不可以的，因为其实专家和普通用户之间的相似本就是两类人群牵强的相似，于是这种推荐效果其实往往不见得好。这一点也许在QQ音乐这样大众的音乐软件中会尤为明显，专家用户会去听民谣，听R&B，但是大多数的新用户只需要听大众流行，听凤凰传奇就已经够了。

3.专家推荐的工程应用

A. 专家推荐用作在线推荐。这属于Online推荐的取巧方法。最简单的实时推荐方法，我们需要离线计算Item之间的相似度，然后根据最近反馈的若干Item，根据相似度计算得到推荐Item，这属于典型的Item-based的思路。那么很多人攻击User-based不适合做实时推荐，不适合冷启动。其实我们可以把专家推荐作为User-based的退化方式。因为专家用户有限，所以我们完全可以将专家数据常驻内存，从而可以实时计算用户和专家的相似度，得到推荐结果。

B. 将专家推荐用作社区运营引导。我们如何选择专家？这是有很多猫腻可以做的。如果我们用传统的Item-based做推荐，如果希望在推荐内容中插入一条广告，就需要在代码中插入一些很脏的代码，但是专家推荐完全可以解决这样的问题，因为只需要把某一个运营账号设置为专家就好了。

4.专家推荐的工程经验和风险弊端

A. 如何选择专家？专家推荐中最重要的环节就是专家的选择，一般的专家选择就是通过制定一些规则来自动挑选，例如通过观影数，听过的歌曲数。但是有几点却是大多人忽略的：

第一，避免让专家形成“专家孤岛”，简单来说，我们希望希望专家的Item可以覆盖到所有的Item，这样可以达到更全面的推荐效果，但是如果我们选择了不恰当的专家时，极有可能出现孤岛的情况。我举个曾经的例子，之前我在豆瓣工作时，尝试过使用TrustRank来迭代计算每个人的Rank值，TrustRank的原理其实就是选择专家，然后逐渐扩散开，我的做法是选择那些关注超过N的用户，但是最后上线用作某项目时，才发现很多用户的Rank值是零，也就是说我选择的专家用户所形成的User-Item二部图其实只覆盖到了很少的Item；这会造成非常致命的问题，所以我建议在选择完专家用户后，一定要确认Item的覆盖率。 

第二，不同领域的专家要均匀分布。如果我们可以满足第一条，于是大家会对整体的样本中做随机抽样，这样会导致专家的领域数量分布和全局的领域数量分布接近，而非均匀分布。这表面看上去似乎没有问题，但是实际上却会对冷启动造成非常大的影响。我们思考一个实际的场景，当一个用户刚刚进入的时候，他听了两首歌，这两首歌其实一首小清新民谣，一首重金属摇滚，但是由于专家用户中有100位民谣用户，而只有2位摇滚用户，所以在计算相似度的时候，会通过数量差距，给用户推荐民谣的歌，而没办法推荐重金属摇滚的歌，从而造成用户流失。

第三，专家要符合业务逻辑。其实这一点就对应于我之前所提到的推荐有偏的问题，到底什么是专家？听歌多算不算专家，观影多算不算专家，其实这都不一定算。如果解决冷启动问题，那么也许一些刚刚从“新生期”度过到“成长期”的用户就是专家用户，因为他们已经成功留在了我们的平台上，他们的经验就值得后来者借鉴学习。

B. 避免马太效应，羊群效应。由于专家推荐很难推荐出长尾的Item，于是会造成推荐的Item越来越热，最终导致马太效应越来越严重。另外，“专家用户”一定程度上影响决定了整个社区的“调性”，专家用户给我推荐了《红楼梦》，我觉得专家都打了高分，那么我也去打高分，于是就形成了羊群效应。

C. 推荐系统的攻击。随着推荐系统会带来越来越多的经济利益，对于推荐系统的攻击和Spammer行为也愈演愈烈。恰恰专家系统是最容易被攻破的，攻击者完全可以通过识别专家的筛选规则，将自己“假扮”为专家用户，从而对推荐系统发生攻击。另外，更容易攻破专家系统的其实还不是技术，而是人本身，一旦看到某位专家推荐，只要有着足够的经济利益，那么通过合理的价钱去和专家达成共识，系统就被轻易攻破了。这其实也是我反对某些APP、某些网站通过人工置顶、专家评分的最大理由。

5.写在最后

我在两篇文章中介绍了专家推荐的大致算法、思路以及我在工作过程中遇到的一些问题和工程经验，希望能给大家带来帮助。

## 关于推送，你可能忽略的那些事儿

Push是维持APP留存率最重要的方法之一，但是大多数APP开发者都没有正确意识到Push的意义，也没有建立起一套评估Push质量的方法。Push是一个典型的双刃剑，如果使用的好可以帮你提升留存率，可是使用不当，甚至滥用将会成为你APP的噩梦。但是不幸的是，我看到的大多是Push的不当使用。

1.给用户一个允许推送的理由

之前看过一篇文章讲的很好，大概的意思是说你要任何事情的时候都请给一个需要的理由。作为APP开发者我们都知道，用户很少会反悔从前做过的设置。我举个简单的例子，如果用户在最初的时候禁止你访问他的通讯录，可能你就再也没有机会访问他的通讯录了。同理，如果用户最初的时候禁止你的推送消息，那么你可能就再也没有机会去为用户发送推送通知了。

所以在希望用户授予推送权限时，一定要给用户一个清晰的理由。以滴滴打车作为举例，如果一个用户第一次打开滴滴打车，就弹出窗口说，你是否允许APP为你推送消息，也许这个时候的通过率只有30%-50%左右。但是我们试想这样一个场景，当用户第一次打车时，APP提示说，允许弹出窗口可以让你在退出APP后依然收到司机的接单信息。那么这个时候被用户允许的概率就大大增大了。

2.忽略Push设置

我们追溯一下Push的鼻祖，在PC Web时代我们如何做类似的事情，我们往往做一个网站，然后用Email通知用户各类的通知。以豆瓣来举例：我们可以通过Web设置在什么情况下会被Email通知，例如被关注，被豆邮，日记被评论等等。但是我们却不幸地发现，大多数的APP却没有对推送做这样细致的区分。

请大家意识到，Push的设置其实比Email的设置重要得多，因为当你去发不当的邮件去“打扰”用户时，用户最多把Email忽略，或者作为垃圾邮件。但是当你用不当地推送去打扰用户时，用户去删除APP远远比去手机的设置中去关闭推送容易得多！

所以请更细致地去设置你的推送，什么情况下需要推送？什么时候允许推送？是否需要接受更新通知等等等等。

3.错误评价Push效果

我们在和一些客户做交流时，每个客户关心的问题大体如此：

A. 你们的到达率是多少？ — 这是客户评价我们推送质量的指标

B. 大多数APP的点击率是多少？ — 这是客户评价自己推送质量的指标

其实这是最典型的错误评价Push的指标，我们逐步来说：

A. 什么是到达率？其实在业界，并没有到达率的官方定义，其根本原因在于你无法定义什么叫做到达？是在线用户全部送达？那离线用户呢？离线用户多久送达算做送达？当客户问出这样的问题时，我往往并不愿意用官方的措辞去抛出一个漂亮的数字，而是更愿意去纠正客户的认知错误。

B. 而对于第二个问题，几乎是每个客户都会犯的错误。用户点击率越高越好么？答案是否定的。如我之前所说，推送是把双刃剑，用的好，他提高了APP的留存率，也就是通过推送增加了APP的打开数；但是用的不好，也如之前所说，用户关闭掉推送，甚至卸载掉APP。所以单单去看到点击数，而忽略了消极的影响是非常错误的评价指标。除了点击率，我们更需要去关注，这一次的推送目标，在下一次有多少已经是无法推送的，例如本次推送了用户编号1-100的用户，但是再一天后，1-100只有1-10是可达的，我们说本次推送的次日留存率只有10%，这样即便打开率是90%，也许都是一次不好的推送。

4.设置合理的推送时间

这一点无须多说，大多的APP都知道我们要设置合理的推送推送，例如要在中午12点，下午6点左右发送推送可以获得较高的关注度和打开率。但是所有APP都没有关注到的一点是，是不是所有的用户都应该在这个时间段去推送，其实也就是我们并没有关注到推送时间的个性化，以及推送消息本身和推送时间之间的关系。

5.合理设置推送声音

推送声音与推送本身一样，都是双刃剑。在前文中，我们知道，不当地推送会让用户关闭系统推送，甚至卸载掉APP。在上一段中，我们也知道，在不合理的时间去推送消息，会对用户造成打扰。那么到底是什么对用户造成打扰？其实就是推送声音本身。那么合理地利用推送声音其实也是合理推送很重要的一部分，而且也可以创造出很多不同的用法。例如我们可以对夜间的推送设置无声音；例如我们可以对“不确定的推送“(也就是新用户)设置无声模式等等。

6.对Push一样进行A-B Test和灰度上线

做应用开发的人一定不陌生这两个概念，A-B测试和灰度上线。在推送领域，这一点依然重要，当我们发送一条广播消息时，我们并不确定这条消息的质量是好是坏，打开率如何，那么我们不妨先推送一小部分用户，看看打开率，留存率，然后再做进一步的推送。

